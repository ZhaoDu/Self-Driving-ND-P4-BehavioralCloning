{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data log\n",
    "def getLines(log_filepath):\n",
    "    \"\"\"\n",
    "    Returns the lines from a driving log with base directory `log_filepath`.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    with open(log_filepath) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for line in reader:\n",
    "            lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data \n",
    "def load_data(log_filepath, img_filepath, correction = 0.23):\n",
    "    \"\"\"\n",
    "    Returns the lines from a driving log with base directory `log_filepath`.\n",
    "    \"\"\"\n",
    "    lines = getLines(log_filepath)\n",
    "    images = []\n",
    "    measurements = []\n",
    "    for line in lines:\n",
    "        for source_path in line[0:3]:\n",
    "            filename = source_path.split('\\\\')[-1]\n",
    "            current_path = img_filepath + filename\n",
    "            measurement = float(line[3])\n",
    "            if source_path == line[1]:\n",
    "                measurement = measurement + correction\n",
    "            if source_path == line[2]:\n",
    "                measurement = measurement - correction            \n",
    "            image = np.asarray(Image.open(current_path))\n",
    "            images.append(image)\n",
    "            measurements.append(measurement)\n",
    "    # print('data set size: %d' %(len(measurements)))\n",
    "    return images, measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augumentation \n",
    "def random_flip(image, measurement):\n",
    "    \"\"\"\n",
    "    Horizontal flip the image\n",
    "    \"\"\"\n",
    "    if np.random.rand() > 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        measurement = measurement*-1\n",
    "    return image, measurement\n",
    "\n",
    "def random_translate(image, measurement, range_x=100, range_y=10):\n",
    "    \"\"\"\n",
    "    Randomly shift the image vertically and horizontally \n",
    "    \"\"\"\n",
    "    trans_x = range_x*(np.random.rand() - 0.5)\n",
    "    trans_y = range_y*(np.random.rand() - 0.5)\n",
    "    measurement += trans_x*0.002\n",
    "    trans_m = np.mat([[1.0, 0.0, trans_x],[0.0, 1.0, trans_y]])\n",
    "    height, width = image.shape[:2]\n",
    "    image = cv2.warpAffine(image, trans_m, (width, height))\n",
    "    return image, measurement\n",
    "\n",
    "def random_shadow(image):\n",
    "    \"\"\"\n",
    "    Generates and adds random shadow\n",
    "    \"\"\"\n",
    "    x1, y1 = image.shape[1]*np.random.rand(), 0\n",
    "    x2, y2 = image.shape[1]*np.random.rand(), image.shape[0]\n",
    "    xm, ym = np.mgrid[0:image.shape[0], 0:image.shape[1]]\n",
    "\n",
    "    mask = np.zeros_like(image[:, :, 1])\n",
    "    mask[(ym - y1) * (x2 - x1) - (y2 - y1) * (xm - x1) > 0] = 1\n",
    "\n",
    "    cond = mask == np.random.randint(2)\n",
    "    s_ratio = np.random.uniform (low = 0.2, high = 0.5)\n",
    "\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    hls[:, :, 1][cond] = hls[:, :, 1][cond]*s_ratio\n",
    "    return cv2.cvtColor(hls, cv2.COLOR_HLS2RGB)\n",
    "\n",
    "def random_brighness(image):\n",
    "    \"\"\"\n",
    "    Randomly adjust brightness of the image\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    b_ratio = 1.0 + 0.4*(np.random.rand() - 0.5)\n",
    "    hsv[:, :, 2] = hsv[:, :, 2] * b_ratio\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "def data_augumentation(images, measurements):\n",
    "    augumented_images, augumented_measurements = [],[]\n",
    "    for image, measurement in zip(images, measurements):        \n",
    "        augumented_images.append(image)\n",
    "        augumented_measurements.append(measurement)\n",
    "        image, measurement = random_flip(image, measurement)\n",
    "        image, measurement = random_translate (image, measurement)\n",
    "        image = random_shadow(image)\n",
    "        image = random_brighness(image)\n",
    "        augumented_images.append(image)\n",
    "        augumented_measurements.append(measurement)\n",
    "    return augumented_images, augumented_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(samples, batch_size = 256):\n",
    "    num_samples = len(samples)\n",
    "\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        samples = sklearn.utils.shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            angles = []\n",
    "            for image, measurement in batch_samples:\n",
    "                # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                images.append(image)\n",
    "                angles.append(measurement)\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Construction \n",
    "# Creates NVIDIA Autonomous Car Group model\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Lambda, Activation, Cropping2D, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "def model(): \n",
    "    \"\"\"\n",
    "    Creates NVIDIA Autonomous Car Group model\n",
    "    \"\"\"       \n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3))) # Normalizing the data\n",
    "    model.add(Cropping2D(cropping=((50,20), (0,0)))) # Cropping the image\n",
    "    model.add(Convolution2D(24,5,5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(36,5,5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(48,5,5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(64,3,3, activation='relu'))\n",
    "    model.add(Convolution2D(64,3,3, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_2(): \n",
    "    \"\"\"\n",
    "    Creates NVIDIA Autonomous Car Group model\n",
    "    \"\"\"       \n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3))) # Normalizing the data\n",
    "    model.add(Cropping2D(cropping=((50,20), (0,0)))) # Cropping the image\n",
    "    model.add(Convolution2D(24,5,5, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(36,5,5, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(48,5,5, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(64,3,3, activation='relu'))\n",
    "    model.add(Convolution2D(64,3,3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "log_filepath = '../data/driving-data/driving_log.csv'\n",
    "img_filepath = '../data/driving-data/IMG/'\n",
    "images_original, measurements_original = load_data(log_filepath, img_filepath, correction = 0.23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set size: 35916\n"
     ]
    }
   ],
   "source": [
    "images, measurements = data_augumentation(images_original, measurements_original)\n",
    "images, measurements = sklearn.utils.shuffle(images, measurements)\n",
    "print('data set size: %d' %(len(measurements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 28732\n",
      "Validation samples: 7184\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "samples = list(zip(images, measurements))\n",
    "train_samples, validation_samples = train_test_split(samples, test_size = 0.2)\n",
    "\n",
    "print('Train samples: {}'.format(len(train_samples)))\n",
    "print('Validation samples: {}'.format(len(validation_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_generator = generator(train_samples, batch_size = batch_size)\n",
    "validation_generator = generator(validation_samples, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\DeepLearning_GPU\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), activation=\"relu\")`\n",
      "  \n",
      "D:\\ProgramData\\Anaconda3\\envs\\DeepLearning_GPU\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), activation=\"relu\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "D:\\ProgramData\\Anaconda3\\envs\\DeepLearning_GPU\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), activation=\"relu\")`\n",
      "  if sys.path[0] == '':\n",
      "D:\\ProgramData\\Anaconda3\\envs\\DeepLearning_GPU\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "D:\\ProgramData\\Anaconda3\\envs\\DeepLearning_GPU\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "D:\\ProgramData\\Anaconda3\\envs\\DeepLearning_GPU\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "D:\\ProgramData\\Anaconda3\\envs\\DeepLearning_GPU\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., verbose=1, steps_per_epoch=28732, epochs=5, validation_steps=7184)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  358/28732 [..............................] - ETA: 34:04 - loss: 0.0407"
     ]
    }
   ],
   "source": [
    "model = model_2()\n",
    "# Compiling and training the model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch = \\\n",
    "    len(train_samples), validation_data = validation_generator, \\\n",
    "    nb_val_samples = len(validation_samples), \\\n",
    "    nb_epoch = 5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DeepLearning_GPU]",
   "language": "python",
   "name": "conda-env-DeepLearning_GPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
